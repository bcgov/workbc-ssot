load csv
    from 'sources.csv'
    (
        label,
        endpoint,
        datapoint,
        filename,
        sheet,
        range,
        author,
        date,
        period
    )
    into postgresql:///ssot
    target table sources
    with
        skip header = 1,
        fields optionally enclosed by '"',
        fields terminated by ',',
        drop indexes

    before load do
    $$ drop table if exists sources; $$,
    $$ create table if not exists sources
    (
        endpoint text,
        label text,
        period timestamptz,
        datapoint text,
        filename text,
        sheet text,
        range text,
        author text,
        date timestamptz,

        primary key(endpoint, period)
    );
    $$

    after load do
    $$ create index sources_endpoint_idx on sources (endpoint); $$,
    $$ comment on table sources is 'Data sources metadata'; $$,
    $$ comment on column sources.label is 'Source label'; $$,
    $$ comment on column sources.endpoint is 'Dataset name / Database table / API endpoint'; $$,
    $$ comment on column sources.period is 'Dataset validity period start'; $$,
    $$ comment on column sources.datapoint is 'Data point'; $$,
    $$ comment on column sources.filename is 'Source filename'; $$,
    $$ comment on column sources.sheet is 'Source sheet'; $$,
    $$ comment on column sources.range is 'Source range'; $$,
    $$ comment on column sources.author is 'Author'; $$,
    $$ comment on column sources.date is 'Date/time of last update'; $$
;
